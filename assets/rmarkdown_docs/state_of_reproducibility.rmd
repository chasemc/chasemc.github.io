---
title: "Reproducible scientific computing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE, include = TRUE)
```


First, "scientific computing" comes with a lot of connotations. The requirements, scope, and complexity will vary across fields, within fields, and project to project. I can't cover all that here but will try to explain a high-level overview of how I approach the problem of reproducibility within my own work.

So let's start at the top and work our way down.

## Reproducible computers

Unfortunately when creating reproducible scientific software we have to worry about more than just the code that we are writing. 99.99999% of us aren't writing cross-platform, no-dependency code. Therefore, we need to ensure that our code can reproduced on a computer that isn't our own. While having code that works crossplatform is nice it is not a requirement.

There's a couple of layers to consider in the onion of dependency management.

1) What operating system (OS) will my code run on? In my opinion Linux is a great choice here for reasons we'll get into later.
2) Are there OS-level dependencies my code will need? (e.g. glibc)
3) What software language(s) am I going to use? (e.g. Python, R, etc)
4) Are there software-language dependencies my code will need? (e.g. libcurl)
5) Are there external libraries my code will rely on? (e.g. pandas, ggplot2, etc)

So, apart from all the work that you've done writing your cool analysis code/tool, the question you need to ask yourself is- How do I make sure that someone trying to reproduce my code is doing so with all the same #1-5 and the same versions?!?!

The best, most reproducible method would be to create a virtual machine (VM) that contains all the software already installed. However, this is rarely done these days as these VM-images contain the entire operating system plus whatever you install and can quickly bloat into multiple gigabytes. 

One of the most widely used alternatives is Docker (and there are tutorials all over the place). Docker is a viable alternative VMs and is currently what I rely on. You start with a base docker image (e.g. a Linux OS (#1)) and provide whatever commands required to install #2-5 in the list above. The result is a set of instructions to reproducibly build a compute environment. However, there is nuance in this step that is often lost and will lead to irreproducible builds. Where possible, the versions of things installed in steps #2-5 must be pinned to specific versions (e.g. `pandas==1.5.2`).
Additionally, providing "the instructions" (Dockerfile) alone isn't enough for even short-term reproducibility (1-10 years). One example scenario is that a software repositories removes an older version of a dependency, since the dependency is pinned to that versiomn `docker build` will fail to build the image and the user will have to try to update versions and hope things work (often they won't because dependency resolution will fail and multiple version changes will have to be performed). If you want to ensure someone has access to the exact docker environemnt, build the image and then use [docker save](https://docs.docker.com/engine/reference/commandline/save/) to export a tar archive. This can then be uploaded along with information (e.g. in a README) about what version of Docker was used to create the tar archive.

## Reproducible compute environments

C
